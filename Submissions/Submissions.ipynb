{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitted models\n",
    "\n",
    "As all our best models gave quite variable results given the training set, we submitted the following ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set session seed to 1 (disabled GPU, CPU parallelism)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(keras)\n",
    "use_condaenv(\"r-tensorflow\")\n",
    "use_session_with_seed(1)\n",
    "\n",
    "data.train <- read.csv(file.path(\"..\",\"..\", \"data\", \"training_data.csv\"))\n",
    "data.test <- read.csv(file.path(\"..\",\"..\", \"data\", \"test_data.csv\"))\n",
    "\n",
    "data.train <- na.omit(data.train)\n",
    "data.train_PL <- data.train$VALENCE.PLEASANTNESS\n",
    "data.train$VALENCE.PLEASANTNESS <- NULL\n",
    "data.train$SWEETORSOUR <- NULL\n",
    "data.train$Intensity <- as.numeric(data.train$Intensity)\n",
    "\n",
    "data.test <- na.omit(data.test)\n",
    "data.test$Intensity <- as.numeric(data.test$Intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>708</li><li>3028</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 708\n",
       "\\item 3028\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 708\n",
       "2. 3028\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  708 3028"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>68</li><li>3028</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 68\n",
       "\\item 3028\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 68\n",
       "2. 3028\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]   68 3028"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#names(data.test) <- names(data.train)\n",
    "cols = names(data.train[, sapply(data.train, function(v) var(v) != 0)])\n",
    "data.train <- data.train[,cols]\n",
    "dim(data.train)\n",
    "data.test <- data.test[,cols]\n",
    "dim(data.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuronal Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>708</li><li>3028</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 708\n",
       "\\item 3028\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 708\n",
       "2. 3028\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  708 3028"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>68</li><li>3028</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 68\n",
       "\\item 3028\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 68\n",
       "2. 3028\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]   68 3028"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#scaling\n",
    "all_data <- as.matrix(rbind(data.train, data.test))\n",
    "\n",
    "for (i in 1:ncol(all_data)){\n",
    "    max <- max(all_data[,i])\n",
    "    min <- min(all_data[,i])\n",
    "    if (max != 1 & min != 0){\n",
    "        for (j in 1:nrow(all_data)) all_data[j,i] <- (all_data[j,i]-min) / (max-min)\n",
    "    }\n",
    "}\n",
    "\n",
    "#we scale together, and then resplit the data\n",
    "data.train.sc <- all_data[1:708,]\n",
    "data.test.sc <- all_data[709:nrow(all_data),]\n",
    "\n",
    "dim(data.train.sc)\n",
    "dim(data.test.sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_bs_predict <- function(N1, N2){\n",
    "    \n",
    "     nn <- keras_model_sequential() %>%\n",
    "      layer_dense(units = N1, activation = 'relu', input_shape = c(3028)) %>%\n",
    "      layer_dense(units = N2, activation = 'relu',) %>%\n",
    "      layer_dense(units = 1, activation = 'linear')\n",
    "    \n",
    "        #train network\n",
    "        nn %>% compile(\n",
    "            loss = 'mse',\n",
    "            optimizer = 'adam'  \n",
    "        )\n",
    "        history <- nn %>% fit(\n",
    "            data.train.sc,\n",
    "            data.train_PL,\n",
    "            batch_size = 350, # stochastic gradient descent batch size\n",
    "            epochs = 650,\n",
    "            validation_split = 0.25,\n",
    "            callbacks = callback_early_stopping(monitor = \"val_loss\", patience = 10)\n",
    "        )\n",
    "        predict(nn, data.test.sc) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.pred.NN <- NN_bs_predict(600, 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_submission <- data.frame(Id = c(1:68), VALENCE.PLEASANTNESS = y.pred.NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "write.csv(NN_submission, file = 'NN_submission.csv', row.names = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting (best $\\lambda$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(xgboost)\n",
    "boost.pl <- xgboost(as.matrix(data.train), label=data.train_PL, eta=0.00316227766016838, objective=\"reg:squarederror\", max.depth=3, nrounds=1000, verbose = 0)\n",
    "y.pred.boosting1 <- predict(boost.pl, as.matrix(data.test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_submission <- data.frame(Id = c(1:68), VALENCE.PLEASANTNESS = y.pred.boosting1)\n",
    "write.csv(boosting_submission, file='boosting_submission.csv', row.names = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting (hyper-grid, cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(xgboost)\n",
    "boost.pl <- xgboost(as.matrix(data.train), label=data.train_PL, eta=0.1, objective=\"reg:squarederror\", max.depth=1, nrounds=203, verbose = 0)\n",
    "y.pred.boosting2 <- predict(boost.pl, as.matrix(data.test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_submission2 <- data.frame(Id = c(1:68), VALENCE.PLEASANTNESS = y.pred.boosting2)\n",
    "write.csv(boosting_submission2, file='boosting_submission2.csv', row.names = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deuxiÃ¨me meilleur\n",
    "library(xgboost)\n",
    "boost.pl <- xgboost(as.matrix(data.train), label=data.train_PL, eta=0.005, objective=\"reg:squarederror\", max.depth=1, nrounds=2608, verbose = 0)\n",
    "y.pred.boosting2 <- predict(boost.pl, as.matrix(data.test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_submission2 <- data.frame(Id = c(1:68), VALENCE.PLEASANTNESS = y.pred.boosting2)\n",
    "write.csv(boosting_submission2, file='boosting_submission2a.csv', row.names = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(glmnet)\n",
    "\n",
    "#data.train_PL\n",
    "#data.train\n",
    "#data.test\n",
    "\n",
    "cv.lasso1 <- cv.glmnet(as.matrix(data.train), data.train_PL, alpha = 1, nfold = 10)\n",
    "best.lasso1 <- glmnet(as.matrix(data.train), data.train_PL, alpha = 1, lambda = cv.lasso1$lambda.min)\n",
    "y.pred.lasso <- predict(best.lasso1, as.matrix(data.test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_submission <- data.frame(Id = c(1:68), VALENCE.PLEASANTNESS = c(y.pred.lasso))\n",
    "write.csv(lasso_submission, file='lasso_submission.csv', row.names = FALSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
