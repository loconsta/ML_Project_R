{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance of models\n",
    "\n",
    "After tuning all our models, we made a comparison of their variances, given their individual variability dependent on the choice of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(glmnet)\n",
    "library(keras)\n",
    "library(xgboost)\n",
    "\n",
    "data <- read.csv(file.path(\"..\", \"data\", \"training_data.csv\"))\n",
    "data <- na.omit(data)\n",
    "data_PL <- data$VALENCE.PLEASANTNESS\n",
    "data$VALENCE.PLEASANTNESS <- NULL\n",
    "data$SWEETORSOUR <- NULL\n",
    "data$Intensity <- as.numeric(data$Intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>708</li><li>3028</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 708\n",
       "\\item 3028\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 708\n",
       "2. 3028\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  708 3028"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = names(data[, sapply(data, function(v) var(v) != 0)])\n",
    "data <- data[,cols]\n",
    "dim(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "\n",
    "#define lambda once on a random split training/test\n",
    "idx <- sample(nrow(data), 4*nrow(data)/5)\n",
    "\n",
    "#matrix\n",
    "train.x <- as.matrix(data[idx,])\n",
    "train.y <- data_PL[idx]\n",
    "\n",
    "test.x <- as.matrix(data[-idx,])\n",
    "test.y <- data_PL[-idx]\n",
    "    \n",
    "cv.lasso1 <- cv.glmnet(train.x, train.y, alpha = 1, nfold = 10)\n",
    "l <- cv.lasso1$lambda.min\n",
    "\n",
    "#cross-evaluate\n",
    "lasso_cv <- function(seed){\n",
    "    set.seed(seed)\n",
    "    idx <- sample(nrow(data), 4*nrow(data)/5)\n",
    "\n",
    "    #matrix\n",
    "    train.x <- as.matrix(data[idx,])\n",
    "    train.y <- data_PL[idx]\n",
    "\n",
    "    test.x <- as.matrix(data[-idx,])\n",
    "    test.y <- data_PL[-idx]\n",
    "     \n",
    "    best.lasso1 <- glmnet(train.x, train.y, alpha = 1, lambda = l)\n",
    "    y.pred <- predict(best.lasso1, test.x)\n",
    "    lasso1.MSE <- mean((y.pred - test.y)^2)\n",
    "    lasso1.MSE\n",
    "}\n",
    "lasso_MSE <- sapply(1:50, lasso_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost.cv <- function(seed){\n",
    "    set.seed(seed)\n",
    "    idx <- sample(nrow(data), 4*nrow(data)/5)\n",
    "\n",
    "    #matrix\n",
    "    train.x <- as.matrix(data[idx,])\n",
    "    train.y <- data_PL[idx]\n",
    "\n",
    "    test.x <- as.matrix(data[-idx,])\n",
    "    test.y <- data_PL[-idx]\n",
    " \n",
    "    \n",
    "    boost.pl <- xgboost(train.x, label=train.y, eta=0.00316227766016838, objective=\"reg:squarederror\", max.depth=3, nrounds=1000, verbose = 0)\n",
    "    y.pred <- predict(boost.pl, test.x)\n",
    "    test.error <- mean((y.pred - test.y)^2) \n",
    "    test.error\n",
    "    \n",
    "}\n",
    "boost_MSE <- sapply(1:50, boost.cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost.cv2 <- function(seed){\n",
    "    set.seed(seed)\n",
    "    idx <- sample(nrow(data), 4*nrow(data)/5)\n",
    "\n",
    "    #matrix\n",
    "    train.x <- as.matrix(data[idx,])\n",
    "    train.y <- data_PL[idx]\n",
    "\n",
    "    test.x <- as.matrix(data[-idx,])\n",
    "    test.y <- data_PL[-idx]\n",
    "    \n",
    "    boost.pl2 <- xgboost(train.x, label=train.y, eta=0.1, objective=\"reg:squarederror\", max.depth=1, nrounds=132, verbose = 0)\n",
    "    y.pred <- predict(boost.pl2, test.x)\n",
    "    test.error2 <- mean((y.pred - test.y)^2) \n",
    "    test.error2\n",
    "    \n",
    "}\n",
    "boost_MSE2 <- sapply(1:50, boost.cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i in 1:ncol(data)){\n",
    "    max <- max(data[,i])\n",
    "    min <- min(data[,i])\n",
    "    if (max != 1 & min != 0){\n",
    "        for (j in 1:nrow(data)) data[j,i] <- (data[j,i]-min) / (max-min)\n",
    "    }\n",
    "}\n",
    "\n",
    "NN_one_cv <- function(seed){\n",
    "    set.seed(seed)\n",
    "    \n",
    "    idx <- sample(nrow(data), 4*nrow(data)/5)\n",
    "    train.y <- data_PL[idx]\n",
    "    test.y <- data_PL[-idx]\n",
    "\n",
    "    data <- as.matrix(data)\n",
    "    #training and test scaled predictors sets\n",
    "    train.x <- data[idx,]\n",
    "    test.x <- data[-idx,]\n",
    "    \n",
    "     nn <- keras_model_sequential() %>%\n",
    "      layer_dense(units = 400, activation = 'relu', input_shape = c(3028)) %>%\n",
    "      layer_dense(units = 1, activation = 'linear')\n",
    "    \n",
    "        #train network\n",
    "        nn %>% compile(\n",
    "            loss = 'mse',\n",
    "            optimizer = 'adam'  \n",
    "        )\n",
    "        history <- nn %>% fit(\n",
    "            train.x,\n",
    "            train.y,\n",
    "            batch_size = 350, # stochastic gradient descent batch size\n",
    "            epochs = 650,\n",
    "            validation_split = 0.25,\n",
    "            callbacks = callback_early_stopping(monitor = \"val_loss\", patience = 10)\n",
    "        )\n",
    "        y.pred <- predict(nn, test.x) #fixed test set\n",
    "        MSE <- mean((y.pred - test.y)^2)\n",
    "        MSE\n",
    "}\n",
    "\n",
    "NN_two_cv <- function(seed){\n",
    "    set.seed(seed)\n",
    "    \n",
    "    idx <- sample(nrow(data), 4*nrow(data)/5)\n",
    "    train.y <- data_PL[idx]\n",
    "    test.y <- data_PL[-idx]\n",
    "\n",
    "    data <- as.matrix(data)\n",
    "    #training and test scaled predictors sets\n",
    "    train.x <- data[idx,]\n",
    "    test.x <- data[-idx,]\n",
    "    \n",
    "     nn <- keras_model_sequential() %>%\n",
    "      layer_dense(units = 600, activation = 'relu', input_shape = c(3028)) %>%\n",
    "      layer_dense(units = 100, activation = 'relu',) %>%\n",
    "      layer_dense(units = 1, activation = 'linear')\n",
    "    \n",
    "        #train network\n",
    "        nn %>% compile(\n",
    "            loss = 'mse',\n",
    "            optimizer = 'adam'  \n",
    "        )\n",
    "        history <- nn %>% fit(\n",
    "            train.x,\n",
    "            train.y,\n",
    "            batch_size = 350, # stochastic gradient descent batch size\n",
    "            epochs = 650,\n",
    "            validation_split = 0.25,\n",
    "            callbacks = callback_early_stopping(monitor = \"val_loss\", patience = 10)\n",
    "        )\n",
    "        y.pred <- predict(nn, test.x) #fixed test set\n",
    "        MSE <- mean((y.pred - test.y)^2)\n",
    "        MSE\n",
    "}\n",
    "\n",
    "NN_two_MSE <- sapply(1:50, NN_two_cv)\n",
    "NN_one_MSE <- sapply(1:50, NN_one_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAABNTU1oaGh8fHyM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\nRAIQAJEABPgfscc4k+M2b04AAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title \"Variances of models\""
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res <- data.frame(boost_tuned = boost_MSE**0.5, boost_cv = boost_MSE2**0.5, NN_1 = NN_one_MSE**0.5, NN_2 = NN_two_MSE**0.5, linreg = lasso_MSE**0.5)\n",
    "boxplot(res, ylab = \"RMSE\",  col = 'pink', ylim = c(18, 25))\n",
    "title('Variances of models')\n",
    "grid(12, lw = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
